#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TikTok API23 ì‹¤ì œ ì‘ë™ ë²„ì „
ê²€ì¦ëœ ì—”ë“œí¬ì¸íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
"""

import os
import sys
import json
import time
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.settings import (
    TIKTOK_API23_KEY, TIKTOK_API23_BASE_URL, 
    BRAND_KEYWORDS, TIKTOK_HASHTAG_KEYWORDS
)

class TikTokAPI:
    def __init__(self, rapidapi_key=None):
        """ì‹¤ì œ ì‘ë™í•˜ëŠ” TikTok API23 í´ë¼ì´ì–¸íŠ¸"""
        self.rapidapi_key = rapidapi_key or TIKTOK_API23_KEY
        self.base_url = TIKTOK_API23_BASE_URL
        self.request_count = 0
        
        # RapidAPI í—¤ë”
        self.headers = {
            "X-RapidAPI-Key": self.rapidapi_key,
            "X-RapidAPI-Host": "tiktok-api23.p.rapidapi.com"
        }
        
        # ê²€ì¦ëœ ì—”ë“œí¬ì¸íŠ¸ë“¤ (updated to working endpoints)
        self.endpoints = {
            'search_video': f"{self.base_url}/api/search/video",  # NEW: Video search
            'trending': f"{self.base_url}/api/post/trending",      # NEW: Trending posts
            'user_posts': f"{self.base_url}/api/user/posts",
            'challenge_info': f"{self.base_url}/api/challenge/info"
        }
        
        # ìš”ì²­ ì œí•œ
        self.request_delay = 1
    
    def get_comprehensive_video_data(self, keyword: str, region_code: str = "US", 
                                   max_results: int = 50, published_after=None, 
                                   order: str = "relevance") -> Tuple[List[Dict], List[str]]:
        """
        í‚¤ì›Œë“œë¡œ TikTok ë¹„ë””ì˜¤ ê²€ìƒ‰ í›„ ëª¨ë“  ì •ë³´ë¥¼ ìˆ˜ì§‘
        ë‹¤ì¤‘ ì „ëµ: ì¼ë°˜ê²€ìƒ‰ + ì‚¬ìš©ìê²€ìƒ‰ + í•´ì‹œíƒœê·¸ê²€ìƒ‰
        """
        try:
            print(f"TikTok API search starting: {keyword} (region: {region_code})")
            
            all_videos = []
            all_video_ids = []

            # ì „ëµ 1: ë¹„ë””ì˜¤ ê²€ìƒ‰ìœ¼ë¡œ ì§ì ‘ ë¹„ë””ì˜¤ ì°¾ê¸° (NEW - ë©”ì¸ ì „ëµ)
            videos_from_search = self._search_video(keyword, max_results)
            all_videos.extend(videos_from_search)
            
            # ì¤‘ë³µ ì œê±° ë° ë°ì´í„° ë³€í™˜
            unique_videos = self._remove_duplicates(all_videos)
            video_data = []
            video_ids = []
            
            for video in unique_videos[:max_results]:
                try:
                    video_info = self._convert_to_youtube_format(video, keyword, region_code)
                    if video_info:
                        video_data.append(video_info)
                        video_ids.append(video_info['video_id'])
                except Exception as e:
                    print(f"ë¹„ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
                    continue
            
            print(f"[OK] TikTok API search complete: {keyword} - {len(video_data)} videos")
            return video_data, video_ids
            
        except Exception as e:
            print(f"[ERROR] TikTok API search failed: {e}")
            return [], []
    
    def search_multiple_keywords(self, keywords: List[str] = None, region_code: str = "US", 
                                max_results_per_keyword: int = 20) -> Tuple[List[Dict], List[str]]:
        """
        ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ í•œë²ˆì— ê²€ìƒ‰
        """
        if keywords is None:
            keywords = BRAND_KEYWORDS[:5]  # ê¸°ë³¸ê°’: ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
        
        print(f"Multi-keyword search starting: {len(keywords)} keywords")
        print(f"Keyword list: {keywords}")
        
        all_videos = []
        all_video_ids = []
        
        for i, keyword in enumerate(keywords):
            try:
                print(f"\n[{i+1}/{len(keywords)}] í‚¤ì›Œë“œ: '{keyword}'")
                
                videos, video_ids = self.get_comprehensive_video_data(
                    keyword=keyword,
                    region_code=region_code,
                    max_results=max_results_per_keyword
                )
                
                all_videos.extend(videos)
                all_video_ids.extend(video_ids)
                
                print(f"  Collected: {len(videos)} videos")
                
                # API ìš”ì²­ ê°„ê²©
                if i < len(keywords) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´
                    time.sleep(self.request_delay)
                    
            except Exception as e:
                print(f"  [ERROR] Keyword '{keyword}' search failed: {e}")
                continue
        
        # ì „ì²´ ì¤‘ë³µ ì œê±°
        unique_videos = self._remove_duplicates(all_videos)
        unique_video_ids = list(set(all_video_ids))
        
        print(f"\n[OK] Multi-keyword search complete!")
        print(f"Total collected: {len(unique_videos)} unique videos")
        print(f"Duplicates removed: {len(all_videos) - len(unique_videos)}")
        
        return unique_videos, unique_video_ids
    
    def _search_video(self, keyword: str, max_results: int) -> List[Dict]:
        """ë¹„ë””ì˜¤ ê²€ìƒ‰ API ì‚¬ìš© (NEW - /api/search/video)"""
        try:
            print(f"  [Search] Video search: {keyword}")

            params = {
                'keyword': keyword,
                'count': str(min(max_results, 20))
            }

            response = requests.get(
                self.endpoints['search_video'],
                headers=self.headers,
                params=params,
                timeout=10
            )
            self.request_count += 1

            if response.status_code != 200:
                print(f"    [ERROR] Video search failed: {response.status_code}")
                return []

            data = response.json()
            # NEW: Use item_list instead of data
            videos = data.get('item_list', [])

            print(f"    [OK] Video search success: {len(videos)} videos")
            return videos

        except Exception as e:
            print(f"    [ERROR] Video search error: {e}")
            return []
    
    def _search_by_hashtag(self, keyword: str, max_results: int) -> List[Dict]:
        """í•´ì‹œíƒœê·¸ ì •ë³´ API ì‚¬ìš©"""
        try:
            # í‚¤ì›Œë“œë¥¼ í•´ì‹œíƒœê·¸ í˜•íƒœë¡œ ë³€í™˜
            hashtag_name = keyword.replace(' ', '').replace('#', '')
            
            print(f"  [Hashtag] Searching: #{hashtag_name}")
            
            params = {
                'challengeName': hashtag_name,
                'count': str(min(max_results, 20))
            }
            
            response = requests.get(
                self.endpoints['challenge_info'],
                headers=self.headers,
                params=params,
                timeout=10
            )
            self.request_count += 1
            
            if response.status_code != 200:
                print(f"    [ERROR] Hashtag search failed: {response.status_code}")
                return []
            
            data = response.json()
            # í•´ì‹œíƒœê·¸ ì •ë³´ì—ì„œ ë©”íƒ€ë°ì´í„° ìƒì„± (ì‹¤ì œ ë¹„ë””ì˜¤ëŠ” ì—†ìŒ)
            videos = self._create_hashtag_placeholder(data, hashtag_name)
            
            print(f"    [OK] Hashtag info collected: {len(videos)}")
            return videos
            
        except Exception as e:
            print(f"    [ERROR] Hashtag search error: {e}")
            return []
    
    def _search_user_videos(self, keyword: str, max_results: int) -> List[Dict]:
        """ì‚¬ìš©ì ë¹„ë””ì˜¤ ê²€ìƒ‰ (DEPRECATED - not used in new strategy)"""
        # Not used anymore - direct video search is more effective
        return []
    
    def _get_user_posts(self, user_info: Dict, max_results: int) -> List[Dict]:
        """íŠ¹ì • ì‚¬ìš©ìì˜ ê²Œì‹œë¬¼ ê°€ì ¸ì˜¤ê¸°"""
        try:
            sec_uid = user_info.get('sec_uid') or user_info.get('secUid', '')
            if not sec_uid:
                return []
            
            params = {
                'secUid': sec_uid,
                'count': str(min(max_results, 10)),
                'cursor': '0'
            }
            
            response = requests.get(
                self.endpoints['user_posts'],
                headers=self.headers,
                params=params,
                timeout=10
            )
            self.request_count += 1
            
            if response.status_code != 200:
                return []
            
            data = response.json()
            videos = self._extract_videos_from_user_posts(data)
            
            return videos
            
        except Exception as e:
            return []
    
    def _extract_videos_from_search(self, data: Dict) -> List[Dict]:
        """ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¹„ë””ì˜¤ ì¶”ì¶œ"""
        videos = []
        try:
            if 'data' in data and isinstance(data['data'], list):
                for item in data['data']:
                    if item.get('type') == 1:  # ë¹„ë””ì˜¤ íƒ€ì…
                        video_list = item.get('aweme_list', [])
                        videos.extend(video_list)
                    elif 'aweme_list' in item:
                        videos.extend(item['aweme_list'])
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return videos
    
    def _extract_users_from_search_data(self, search_results: List[Dict]) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ"""
        users = []
        try:
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ author ì •ë³´ ì¶”ì¶œ
            for video in search_results:
                if 'author' in video:
                    author = video['author']
                    if author.get('sec_uid') or author.get('secUid'):
                        users.append(author)
        except:
            pass
        
        return users
    
    def _extract_videos_from_user_posts(self, data: Dict) -> List[Dict]:
        """ì‚¬ìš©ì ê²Œì‹œë¬¼ì—ì„œ ë¹„ë””ì˜¤ ì¶”ì¶œ"""
        try:
            if 'data' in data and 'itemList' in data['data']:
                return data['data']['itemList']
        except:
            pass
        return []
    
    def _create_hashtag_placeholder(self, data: Dict, hashtag_name: str) -> List[Dict]:
        """í•´ì‹œíƒœê·¸ ì •ë³´ë¡œë¶€í„° í”Œë ˆì´ìŠ¤í™€ë” ë¹„ë””ì˜¤ ìƒì„±"""
        try:
            challenge_info = data.get('challengeInfo', {}).get('challenge', {})
            if not challenge_info:
                return []
            
            # í•´ì‹œíƒœê·¸ ë©”íƒ€ë°ì´í„°ë¥¼ ë¹„ë””ì˜¤ í˜•íƒœë¡œ ë³€í™˜
            placeholder = {
                'id': f"hashtag_{hashtag_name}_{int(time.time())}",
                'desc': f"#{hashtag_name} í•´ì‹œíƒœê·¸ ì •ë³´",
                'author': {
                    'unique_id': 'tiktok_hashtag',
                    'nickname': f"#{hashtag_name}",
                    'sec_uid': f"hashtag_{hashtag_name}"
                },
                'statistics': challenge_info.get('stats', {}),
                'create_time': int(time.time()),
                'is_hashtag_info': True  # êµ¬ë¶„ìš© í”Œë˜ê·¸
            }
            
            return [placeholder]
            
        except:
            return []
    
    def _remove_duplicates(self, videos: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ë¹„ë””ì˜¤ ì œê±°"""
        seen_ids = set()
        unique_videos = []
        
        for video in videos:
            video_id = video.get('id') or video.get('aweme_id') or str(hash(str(video)))
            if video_id not in seen_ids:
                seen_ids.add(video_id)
                unique_videos.append(video)
        
        return unique_videos
    
    def _convert_to_youtube_format(self, video: Dict, keyword: str, region_code: str) -> Dict[str, Any]:
        """TikTok ë¹„ë””ì˜¤ë¥¼ YouTube í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (Updated for new API response)"""
        try:
            # ë¹„ë””ì˜¤ ID (NEW: using 'id' field from new API)
            video_id = str(video.get('id', '')) or str(video.get('aweme_id', '')) or f"tiktok_{hash(str(video))}"

            # ê¸°ë³¸ ì •ë³´ (NEW: 'desc' field directly)
            desc = video.get('desc', '') or video.get('description', '') or f"TikTok video about {keyword}"

            # ì‘ì„±ì ì •ë³´
            author = video.get('author', {})
            username = author.get('uniqueId', '') or author.get('unique_id', '') or author.get('nickname', '') or 'tiktok_user'

            # í†µê³„ ì •ë³´ (NEW: 'stats' field)
            stats = video.get('stats', {}) or video.get('statistics', {})
            view_count = stats.get('playCount', 0) or stats.get('play_count', 0) or stats.get('view_count', 0) or 1000
            like_count = stats.get('diggCount', 0) or stats.get('digg_count', 0) or stats.get('like_count', 0) or 50
            comment_count = stats.get('commentCount', 0) or stats.get('comment_count', 0) or 10
            share_count = stats.get('shareCount', 0) or stats.get('share_count', 0) or 5

            # ì‹œê°„ ì •ë³´ (NEW: 'createTime' field)
            create_time = video.get('createTime', 0) or video.get('create_time', 0) or int(time.time())
            published_at = datetime.fromtimestamp(create_time).isoformat() + 'Z'
            
            # í•´ì‹œíƒœê·¸ ì •ë³´ì¸ì§€ í™•ì¸
            is_hashtag_info = video.get('is_hashtag_info', False)
            
            return {
                # ê²€ìƒ‰ ê´€ë ¨ ì •ë³´
                'video_id': str(video_id),
                'search_keyword': keyword,
                'search_region': region_code,
                'search_order': 'relevance',
                'collected_at': datetime.now().isoformat(),
                'is_hashtag_info': is_hashtag_info,
                
                # ê¸°ë³¸ ì •ë³´
                'title': desc[:100].replace('\n', ' ').replace('\r', ' '),
                'description': desc.replace('\n', ' ').replace('\r', ' '),
                'channel_id': username,
                'channel_title': username,
                'published_at': published_at,
                'category_id': 'Entertainment',
                'default_language': 'en' if region_code == 'US' else 'ko',
                'default_audio_language': 'en' if region_code == 'US' else 'ko',
                'live_broadcast_content': 'none',
                'tags': keyword,
                
                # ì¸ë„¤ì¼ ì •ë³´
                'thumbnail_default': video.get('video', {}).get('cover', '') or '',
                'thumbnail_medium': video.get('video', {}).get('cover', '') or '',
                'thumbnail_high': video.get('video', {}).get('cover', '') or '',
                'thumbnail_standard': video.get('video', {}).get('cover', '') or '',
                'thumbnail_maxres': video.get('video', {}).get('cover', '') or '',
                
                # í†µê³„ ì •ë³´
                'view_count': int(view_count),
                'like_count': int(like_count),
                'dislike_count': 0,
                'favorite_count': int(share_count),
                'comment_count': int(comment_count),
                
                # ì½˜í…ì¸  ì •ë³´
                'duration_seconds': video.get('video', {}).get('duration', 30),
                'duration_iso': f"PT{video.get('video', {}).get('duration', 30)}S",
                'dimension': '2d',
                'definition': 'hd',
                'caption': 'false',
                'licensed_content': False,
                'content_rating': '{}',
                'projection': 'rectangular',
                'has_custom_thumbnail': True,
                
                # ìƒíƒœ ì •ë³´
                'upload_status': 'processed',
                'privacy_status': 'public',
                'license': 'tiktok',
                'embeddable': True,
                'public_stats_viewable': True,
                'made_for_kids': False,
                'self_declared_made_for_kids': False,
                
                # ì£¼ì œ ì •ë³´
                'topic_ids': '',
                'relevant_topic_ids': '',
                'topic_categories': '',
                
                # ë…¹í™” ì •ë³´
                'recording_date': '',
                'location_latitude': '',
                'location_longitude': '',
                'location_altitude': '',
                
                # ì±„ë„ ì •ë³´
                'channel_subscriber_count': author.get('follower_count', 1000),
                'channel_video_count': author.get('aweme_count', 100),
                'channel_total_view_count': 0,
                'channel_description': author.get('signature', f"TikTok creator: @{username}"),
                'channel_country': region_code,
                'channel_custom_url': f"@{username}",
                'channel_published_at': '',
            }
            
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def get_comprehensive_comments(self, video_ids: List[str], max_comments_per_video: int = 100) -> List[Dict[str, Any]]:
        """
        TikTok APIë¡œ ì‹¤ì œ ëŒ“ê¸€ ìˆ˜ì§‘ (NEW - /api/post/comments)
        """
        print("Collecting real TikTok comments from API...")

        comments_data = []
        for video_id in video_ids[:5]:  # Limit to 5 videos to avoid API quota
            real_comments = self._get_post_comments(video_id, min(max_comments_per_video, 50))
            comments_data.extend(real_comments)
            print(f"Real comments collected: {video_id} - {len(real_comments)} comments")
            time.sleep(1)  # Rate limiting

        return comments_data

    def _get_post_comments(self, video_id: str, max_comments: int) -> List[Dict]:
        """ì‹¤ì œ TikTok ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° (NEW)"""
        try:
            url = f"{self.base_url}/api/post/comments"
            params = {
                'videoId': video_id,  # Correct parameter name!
                'count': str(min(max_comments, 50)),
                'cursor': '0'
            }

            response = requests.get(url, headers=self.headers, params=params, timeout=10)
            self.request_count += 1

            if response.status_code != 200:
                print(f"    [ERROR] Comments API failed: {response.status_code}")
                return []

            data = response.json()
            comments = data.get('comments', [])

            # Convert to YouTube-like format
            formatted_comments = []
            for comment in comments:
                formatted = self._convert_comment_to_youtube_format(comment, video_id)
                if formatted:
                    formatted_comments.append(formatted)

            return formatted_comments

        except Exception as e:
            print(f"    [ERROR] Get comments error: {e}")
            return []

    def _convert_comment_to_youtube_format(self, comment: Dict, video_id: str) -> Dict:
        """TikTok ëŒ“ê¸€ì„ YouTube í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            comment_id = str(comment.get('cid', ''))
            comment_text = comment.get('text', '')
            create_time = comment.get('create_time', int(time.time()))

            # Author info
            user = comment.get('user', {})
            author_name = user.get('nickname', 'TikTok User')
            author_id = user.get('unique_id', '')

            return {
                'video_id': video_id,
                'comment_id': comment_id,
                'comment_type': 'top_level',
                'parent_comment_id': '',
                'collected_at': datetime.now().isoformat(),

                'author_display_name': author_name,
                'author_profile_image_url': user.get('avatar_thumb', {}).get('url_list', [''])[0] if user.get('avatar_thumb') else '',
                'author_channel_url': f"https://tiktok.com/@{author_id}",
                'author_channel_id': author_id,

                'comment_text_display': comment_text,
                'comment_text_original': comment_text,
                'comment_text_length': len(comment_text),

                'like_count': comment.get('digg_count', 0),
                'reply_count': comment.get('reply_comment_total', 0),
                'moderation_status': '',

                'published_at': datetime.fromtimestamp(create_time).isoformat() + 'Z',
                'updated_at': datetime.fromtimestamp(create_time).isoformat() + 'Z',

                'viewer_rating': '',
                'can_rate': True,
            }

        except Exception as e:
            print(f"Comment conversion error: {e}")
            return None
    
    def _create_smart_dummy_comments(self, video_id: str, max_comments: int) -> List[Dict]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë”ë¯¸ ëŒ“ê¸€ ìƒì„±"""
        dummy_comments = []
        comment_count = min(max_comments, 20)
        
        # ë¸Œëœë“œë³„ ëŒ“ê¸€ í…œí”Œë¦¿
        samsung_comments = [
            "ì‚¼ì„± TV ì§„ì§œ í™”ì§ˆ ì¢‹ë„¤ìš”! ğŸ‘",
            "ì´ ëª¨ë¸ ì–´ë–¤ ê±´ê°€ìš”?",
            "QLED í™”ì§ˆ ë¯¸ì³¤ë‹¤ ğŸ˜",
            "The Frame TV ì •ë§ ì˜ˆìˆ ì‘í’ˆ ê°™ì•„ìš”",
            "ì‚¼ì„± ìŠ¤ë§ˆíŠ¸ TV ê¸°ëŠ¥ë“¤ ë„ˆë¬´ ì¢‹ìŒ",
            "ê°€ê²©ëŒ€ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ë„¤ì˜¤ QLED ì¨ë³´ì‹  ë¶„ í›„ê¸° ë¶€íƒí•´ìš”",
            "LGë‘ ë¹„êµí•˜ë©´ ì–´ë•Œìš”?",
            "ì‚¼ì„± TV ì„¤ì¹˜ ì–´ë µë‚˜ìš”?",
            "ì´ê±° ê²Œì„í•˜ê¸° ì¢‹ë‚˜ìš”?",
        ]
        
        general_comments = [
            "í™”ì§ˆ ì§„ì§œ ì¢‹ë„¤ìš”!",
            "ì–´ë””ì„œ ì‚´ ìˆ˜ ìˆë‚˜ìš”?",
            "ê°€ê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ì •ë§ ë©‹ìˆì–´ìš”!",
            "ì´ê±° ì§„ì§œ ì‹ ê¸°í•˜ë‹¤",
            "ë‚˜ë„ í•˜ë‚˜ ì‚¬ê³  ì‹¶ì–´ìš”",
            "í’ˆì§ˆì´ ì¢‹ì•„ ë³´ì—¬ìš”",
            "ë””ìì¸ì´ ì˜ˆì˜ë„¤ìš”",
            "ì‚¬ìš©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
            "í›„ê¸° ê¶ê¸ˆí•´ìš”"
        ]
        
        # ë¹„ë””ì˜¤ IDë¡œ ëŒ“ê¸€ íƒ€ì… ê²°ì •
        if 'samsung' in video_id.lower():
            comment_templates = samsung_comments + general_comments
        else:
            comment_templates = general_comments
        
        for i in range(comment_count):
            comment_text = comment_templates[i % len(comment_templates)]
            
            dummy_comment = {
                # ê¸°ë³¸ ì‹ë³„ ì •ë³´
                'video_id': video_id,
                'comment_id': f"tiktok_comment_{video_id}_{i+1}",
                'comment_type': 'top_level',
                'parent_comment_id': '',
                'collected_at': datetime.now().isoformat(),
                
                # ì‘ì„±ì ì •ë³´
                'author_display_name': f"TikTok User {i+1}",
                'author_profile_image_url': f"https://example.com/avatar_{i+1}.jpg",
                'author_channel_url': f"https://tiktok.com/@user{i+1}",
                'author_channel_id': f"tiktok_user_{i+1}",
                
                # ëŒ“ê¸€ ë‚´ìš©
                'comment_text_display': comment_text,
                'comment_text_original': comment_text,
                'comment_text_length': len(comment_text),
                
                # ìƒí˜¸ì‘ìš© ì •ë³´
                'like_count': 5 + i * 2,
                'reply_count': i % 3,
                'moderation_status': '',
                
                # ì‹œê°„ ì •ë³´
                'published_at': (datetime.now() - timedelta(hours=i)).isoformat() + 'Z',
                'updated_at': (datetime.now() - timedelta(hours=i)).isoformat() + 'Z',
                
                # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
                'viewer_rating': '',
                'can_rate': True,
            }
            
            dummy_comments.append(dummy_comment)
        
        return dummy_comments
    
    def get_quota_usage(self) -> int:
        """í˜„ì¬ API ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
        return self.request_count

    def get_user_info(self, unique_id: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸° (êµ¬ë…ììˆ˜, ë¹„ë””ì˜¤ìˆ˜ ë“±)

        Args:
            unique_id: ì‚¬ìš©ìì˜ uniqueId (ì˜ˆ: @usernameì—ì„œ username ë¶€ë¶„)

        Returns:
            Dict with user info including followerCount, videoCount, etc.
        """
        try:
            url = f"{self.base_url}/api/user/info"
            params = {'uniqueId': unique_id}

            response = requests.get(url, headers=self.headers, params=params, timeout=10)
            self.request_count += 1

            if response.status_code != 200:
                print(f"    [WARN] User info failed for {unique_id}: {response.status_code}")
                return None

            data = response.json()
            user_info = data.get('userInfo', {})
            stats = user_info.get('stats', {})
            user = user_info.get('user', {})

            # í†µê³„ ì •ë³´ ì¶”ì¶œ
            return {
                'follower_count': stats.get('followerCount', 0),
                'following_count': stats.get('followingCount', 0),
                'video_count': stats.get('videoCount', 0),
                'heart_count': stats.get('heartCount', 0),  # ì´ ì¢‹ì•„ìš”ìˆ˜
                'digg_count': stats.get('diggCount', 0),
                'friend_count': stats.get('friendCount', 0),
                'nickname': user.get('nickname', ''),
                'signature': user.get('signature', ''),  # bio/description
                'verified': user.get('verified', False),
                'private_account': user.get('privateAccount', False),
            }

        except Exception as e:
            print(f"    [ERROR] Failed to get user info for {unique_id}: {e}")
            return None